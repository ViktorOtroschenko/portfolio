{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ebe6f51",
   "metadata": {},
   "source": [
    "# Курсовая работа\n",
    "\n",
    "Нужно написать приложение, которое будет считывать и выводить кадры с веб-камеры. В процессе считывания определять что перед камерой находится человек, задетектировав его лицо на кадре. После этого, человек показывает жесты руками, а алгоритм должен считать их и определенным образом реагировать на эти жесты. \n",
    "\n",
    "На то, как система будет реагировать на определенные жесты - выбор за вами. Например, на определенный жест (жест пис), система будет здороваться с человеком. На другой, будет делать скриншот экрана. И т.д.\n",
    "Для распознавания жестов, вам надо будет скачать датасет для жестов рук. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8268d0fd",
   "metadata": {},
   "source": [
    "Для курсовой работы был использован свой датасет, где было смонтировано видео с каждым жестом. Для разметки и сбора данных была использована бибилиотека __mediapipe__.\n",
    "\n",
    "Итогом работы стало, что сеть обучается на наших данных и в режиме просмотра видео (также в режиме онлайн) выводит на экране название знакомого ей жеста. При появлении жеста __'Palm'__ система делает скриншот и записывает картинку в папку, при появлении жеста __'Ok'__ система здоровается с человеком. Также по итогу работы сеть ведет журнал с записями знакомых ей жестов. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eed079",
   "metadata": {},
   "source": [
    "__Загрузим все необходимые библиотеки и начнем:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20a36f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import optim\n",
    "\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "145af6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b87afdf",
   "metadata": {},
   "source": [
    "Создадим функцию для десериализации видео с помощью модуля pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e9f5327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name):\n",
    "    with open('data/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3c9c75",
   "metadata": {},
   "source": [
    "Проверим оборудование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "772da4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7f7687",
   "metadata": {},
   "source": [
    "## Часть 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439bf0fd",
   "metadata": {},
   "source": [
    "Шаг 1. Загрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d77650c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_i = 'data__0'\n",
    "file_ok = 'data__1'\n",
    "file_palm = 'data__2'\n",
    "file_thumb = 'data__3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aed5e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_i = load_data(file_i)\n",
    "data_ok = load_data(file_ok)\n",
    "data_palm = load_data(file_palm)\n",
    "data_thumb = load_data(file_thumb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2bc6e1",
   "metadata": {},
   "source": [
    "Шаг 2. Соединим массивы с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8fecf8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = np.vstack((data_i, data_ok))\n",
    "data_2 = np.vstack((data_palm, data_thumb))\n",
    "data = np.vstack((data_1, data_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3dbebd",
   "metadata": {},
   "source": [
    "Шаг 3. Перемешаем наш итоговый массив с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bbc92d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = np.random.permutation(len(data))\n",
    "data = data[perm]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7daa4b0",
   "metadata": {},
   "source": [
    "Посмотрим что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2ec58620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1232, 64), (1302, 64), (1277, 64), (1281, 64), (5092, 64))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_i.shape, data_ok.shape, data_palm.shape, data_thumb.shape, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1081c32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.05458391e-01,  5.14494717e-01, -6.18022314e-05, ...,\n",
       "         4.75846380e-01, -4.51643705e-01,  3.00000000e+00],\n",
       "       [ 3.97533625e-01,  5.49053490e-01, -4.11624787e-05, ...,\n",
       "         3.44248593e-01, -1.48946017e-01,  1.00000000e+00],\n",
       "       [ 6.18091464e-01,  6.69821143e-01, -6.42927116e-05, ...,\n",
       "         5.63005924e-01,  8.60442072e-02,  3.00000000e+00],\n",
       "       ...,\n",
       "       [ 6.42363131e-01,  5.27218938e-01,  4.95112654e-05, ...,\n",
       "         4.71172720e-01, -6.57133237e-02,  3.00000000e+00],\n",
       "       [ 5.67390680e-01,  7.55060136e-01, -1.77461057e-04, ...,\n",
       "         4.43612635e-01, -5.23953848e-02,  2.00000000e+00],\n",
       "       [ 1.16367780e-01,  5.42504191e-01, -2.50578305e-04, ...,\n",
       "         5.10196567e-01, -5.91915131e-01,  3.00000000e+00]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5875d2",
   "metadata": {},
   "source": [
    "Шаг 4. Создадим классы наших жестов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2ca945fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['I', 'Ok', 'Palm', 'Thumb']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d066b56c",
   "metadata": {},
   "source": [
    "Шаг 5. Разделим наши данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1cf229a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5092, 63), (5092,))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = data[:,:-1]\n",
    "y_data = data[:,-1].astype('int64')\n",
    "X_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d0cf52",
   "metadata": {},
   "source": [
    "Шаг 6. Создадим наш Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "39a8ca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skeleton_Dataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.data = X\n",
    "        self.labels = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) \n",
    "       \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]        \n",
    "        label = self.labels[idx]        \n",
    "        return (item, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "212b15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Skeleton_Dataset(X_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14918dde",
   "metadata": {},
   "source": [
    "Будем использовать 75 % в тренировочную выборку, 25 - в тестовую "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "868c3960",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(0.75*len(dataset)), int(0.25*len(dataset))])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7801af",
   "metadata": {},
   "source": [
    "## Часть 2. Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b5a5f165",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "      \n",
    "        self.output_dim = output_dim\n",
    "        self.fc1 = torch.nn.Linear(input_dim, 256)\n",
    "        self.elu1 = torch.nn.ELU(inplace=True)\n",
    "        self.fc2 = torch.nn.Linear(256, 512)        \n",
    "        self.elu2 = torch.nn.ELU(inplace=True)        \n",
    "        self.dr1 = torch.nn.Dropout(0.5)\n",
    "        self.fc3 = torch.nn.Linear(512, output_dim)\n",
    "        self.sm = torch.nn.Softmax(dim=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        x = self.fc1(x)\n",
    "        x = self.elu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.elu2(x)        \n",
    "        x = self.dr1(x)    \n",
    "        x = self.fc3(x)        \n",
    "        out = self.sm(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0be3c99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (fc1): Linear(in_features=63, out_features=256, bias=True)\n",
       "  (elu1): ELU(alpha=1.0, inplace=True)\n",
       "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (elu2): ELU(alpha=1.0, inplace=True)\n",
       "  (dr1): Dropout(p=0.5, inplace=False)\n",
       "  (fc3): Linear(in_features=512, out_features=4, bias=True)\n",
       "  (sm): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 63\n",
    "output_dim = len(LABELS)\n",
    "net = ResNet(input_dim, output_dim)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "38fe726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "\n",
    "    return LABELS[category_i], category_i\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    \n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c74b36c",
   "metadata": {},
   "source": [
    "## Часть 3. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9f272840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если работаете на гпу, очищаем весь кэш\n",
    "if torch.cuda.is_available(): \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "epochs = 2000\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9974e4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eef192b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 epochs, 15 total_steps per epoch\n"
     ]
    }
   ],
   "source": [
    "total_steps = len(train_loader)\n",
    "print(f'{epochs} epochs, {total_steps} total_steps per epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "86dfec79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 iter : 0 (0m 0s) 1.3877  / I ✗ (Thumb)\n",
      "epoch : 33 iter : 5 (0m 1s) 1.3816  / Ok ✓\n",
      "epoch : 66 iter : 10 (0m 2s) 1.3701  / Ok ✗ (Thumb)\n",
      "epoch : 100 iter : 0 (0m 4s) 1.3502  / Ok ✗ (I)\n",
      "epoch : 133 iter : 5 (0m 5s) 1.3385  / Ok ✗ (Thumb)\n",
      "epoch : 166 iter : 10 (0m 7s) 1.3212  / Ok ✗ (Palm)\n",
      "epoch : 200 iter : 0 (0m 8s) 1.2891  / I ✓\n",
      "epoch : 233 iter : 5 (0m 10s) 1.2384  / Thumb ✓\n",
      "epoch : 266 iter : 10 (0m 11s) 1.1916  / Ok ✓\n",
      "epoch : 300 iter : 0 (0m 12s) 1.1495  / Ok ✗ (Palm)\n",
      "epoch : 333 iter : 5 (0m 14s) 1.0926  / Thumb ✓\n",
      "epoch : 366 iter : 10 (0m 15s) 1.0359  / Ok ✓\n",
      "epoch : 400 iter : 0 (0m 16s) 0.9814  / Ok ✓\n",
      "epoch : 433 iter : 5 (0m 18s) 0.9215  / Palm ✓\n",
      "epoch : 466 iter : 10 (0m 19s) 0.8857  / I ✓\n",
      "epoch : 500 iter : 0 (0m 21s) 0.8642  / Palm ✓\n",
      "epoch : 533 iter : 5 (0m 22s) 0.8435  / Thumb ✓\n",
      "epoch : 566 iter : 10 (0m 24s) 0.8274  / I ✓\n",
      "epoch : 600 iter : 0 (0m 25s) 0.8163  / Ok ✓\n",
      "epoch : 633 iter : 5 (0m 26s) 0.8156  / Thumb ✗ (Palm)\n",
      "epoch : 666 iter : 10 (0m 28s) 0.8064  / I ✓\n",
      "epoch : 700 iter : 0 (0m 29s) 0.8281  / I ✓\n",
      "epoch : 733 iter : 5 (0m 31s) 0.7833  / I ✓\n",
      "epoch : 766 iter : 10 (0m 32s) 0.8128  / Ok ✓\n",
      "epoch : 800 iter : 0 (0m 34s) 0.8069  / I ✓\n",
      "epoch : 833 iter : 5 (0m 35s) 0.7863  / Thumb ✓\n",
      "epoch : 866 iter : 10 (0m 37s) 0.8028  / Thumb ✓\n",
      "epoch : 900 iter : 0 (0m 38s) 0.8046  / Ok ✓\n",
      "epoch : 933 iter : 5 (0m 39s) 0.8110  / Thumb ✓\n",
      "epoch : 966 iter : 10 (0m 41s) 0.7949  / I ✓\n",
      "epoch : 1000 iter : 0 (0m 42s) 0.7837  / Ok ✓\n",
      "epoch : 1033 iter : 5 (0m 44s) 0.8004  / Ok ✓\n",
      "epoch : 1066 iter : 10 (0m 45s) 0.8050  / Palm ✓\n",
      "epoch : 1100 iter : 0 (0m 46s) 0.7815  / I ✓\n",
      "epoch : 1133 iter : 5 (0m 48s) 0.8015  / Palm ✓\n",
      "epoch : 1166 iter : 10 (0m 49s) 0.7640  / I ✓\n",
      "epoch : 1200 iter : 0 (0m 51s) 0.7788  / I ✓\n",
      "epoch : 1233 iter : 5 (0m 52s) 0.7758  / Thumb ✓\n",
      "epoch : 1266 iter : 10 (0m 53s) 0.7821  / Thumb ✓\n",
      "epoch : 1300 iter : 0 (0m 55s) 0.7746  / Thumb ✓\n",
      "epoch : 1333 iter : 5 (0m 56s) 0.7813  / I ✓\n",
      "epoch : 1366 iter : 10 (0m 58s) 0.7857  / Palm ✓\n",
      "epoch : 1400 iter : 0 (0m 59s) 0.7866  / Thumb ✓\n",
      "epoch : 1433 iter : 5 (1m 0s) 0.7757  / Ok ✓\n",
      "epoch : 1466 iter : 10 (1m 2s) 0.7904  / Palm ✓\n",
      "epoch : 1500 iter : 0 (1m 3s) 0.7756  / Thumb ✗ (Palm)\n",
      "epoch : 1533 iter : 5 (1m 5s) 0.7867  / Palm ✓\n",
      "epoch : 1566 iter : 10 (1m 6s) 0.7737  / Thumb ✓\n",
      "epoch : 1600 iter : 0 (1m 8s) 0.7696  / Ok ✓\n",
      "epoch : 1633 iter : 5 (1m 9s) 0.7804  / Ok ✓\n",
      "epoch : 1666 iter : 10 (1m 10s) 0.7672  / Thumb ✓\n",
      "epoch : 1700 iter : 0 (1m 12s) 0.7594  / Palm ✓\n",
      "epoch : 1733 iter : 5 (1m 13s) 0.7750  / Ok ✓\n",
      "epoch : 1766 iter : 10 (1m 15s) 0.7894  / I ✓\n",
      "epoch : 1800 iter : 0 (1m 16s) 0.7826  / I ✓\n",
      "epoch : 1833 iter : 5 (1m 17s) 0.7919  / Thumb ✓\n",
      "epoch : 1866 iter : 10 (1m 19s) 0.8060  / Palm ✓\n",
      "epoch : 1900 iter : 0 (1m 20s) 0.7673  / Thumb ✓\n",
      "epoch : 1933 iter : 5 (1m 22s) 0.7730  / Ok ✓\n",
      "epoch : 1966 iter : 10 (1m 23s) 0.7855  / I ✓\n"
     ]
    }
   ],
   "source": [
    "all_losses = []\n",
    "start = time.time()\n",
    "counter = 0\n",
    "for epoch in range(epochs):  \n",
    "    current_loss = 0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        output = net(inputs.float())\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        current_loss += loss.item()\n",
    "        category = LABELS[int(labels[0])]\n",
    "\n",
    "        if counter % 500 == 0:\n",
    "            guess, guess_i = categoryFromOutput(output)\n",
    "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "            print('epoch : %d iter : %d (%s) %.4f  / %s %s' % (epoch, i, timeSince(start), loss, guess, correct))\n",
    "        \n",
    "        counter = counter + 1\n",
    "    if counter % 100 == 0:\n",
    "        all_losses.append(current_loss / 25)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "351ee068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'losses vs. No. of epochs')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = [np.mean(loss) for loss in all_losses]\n",
    "plt.plot(losses, '-x')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('losses')\n",
    "plt.title('losses vs. No. of epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "76b01eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network:   97.56480754124117\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "right = 0\n",
    "counter = 0\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        counter = counter + 1\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)  \n",
    "        output = net(inputs.float())\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        category = LABELS[int(labels[0])]\n",
    "        \n",
    "        if guess == category:\n",
    "            right = right + 1\n",
    "\n",
    "\n",
    "print('Accuracy of the network:  ',  (100 * right / counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b9beb3",
   "metadata": {},
   "source": [
    "Сохраним нашу модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "273e11b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'model_2000_epochs.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ece31d",
   "metadata": {},
   "source": [
    "Загрузим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "841d852c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (fc1): Linear(in_features=63, out_features=256, bias=True)\n",
       "  (elu1): ELU(alpha=1.0, inplace=True)\n",
       "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (elu2): ELU(alpha=1.0, inplace=True)\n",
       "  (dr1): Dropout(p=0.5, inplace=False)\n",
       "  (fc3): Linear(in_features=512, out_features=4, bias=True)\n",
       "  (sm): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ResNet(input_dim, output_dim).to(device)\n",
    "net.load_state_dict(torch.load('model_2000_epochs.pth'))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31826ebd",
   "metadata": {},
   "source": [
    "## 4. Прототип приложения для определения человека и жестов рук перед веб-камерой или по видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cdbe0c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция рисования найденных параметров на кадре\n",
    "def draw(frame, boxes, probs, landmarks):\n",
    "    try:\n",
    "        for box, prob, ld in zip(boxes, probs, landmarks):\n",
    "            # Рисуем обрамляющий прямоугольник лица на кадре\n",
    "            cv2.rectangle(frame,\n",
    "                          (int(box[0]), int(box[1])),\n",
    "                          (int(box[2]), int(box[3])),\n",
    "                          (240, 15, 201),\n",
    "                          thickness=3)\n",
    "\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "704339f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For video input:\n",
    "# file_name = \"121.mp4\"\n",
    "# cap = cv2.VideoCapture(file_name)  \n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture('http://192.168.1.2:8080/video') # В качестве веб-камеры использовал телефон  \n",
    "\n",
    "mtcnn = MTCNN()\n",
    "gesture_name = []\n",
    "pre_char=''\n",
    "current_char=''\n",
    "count = 0\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.75,\n",
    "    min_tracking_confidence=0.75,\n",
    "    max_num_hands=1) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            break\n",
    "            # continue\n",
    "            \n",
    "        scale_percent = 50    \n",
    "        width  = int(image.shape[1] * scale_percent / 100)\n",
    "        height = int(image.shape[0] * scale_percent / 100)\n",
    "\n",
    "        # dsize\n",
    "        dsize = (width, height)    \n",
    "\n",
    "        # resize image\n",
    "        image = cv2.resize(image, dsize)\n",
    "        try:        \n",
    "            boxes, probs, landmarks = mtcnn.detect(image, landmarks=True)                \n",
    "            image = draw(image, boxes, probs, landmarks)        \n",
    "        except:\n",
    "            pass\n",
    "                \n",
    "        palm_vector_list = []\n",
    "        \n",
    "        # Flip the image horizontally for a later selfie-view display, and convert\n",
    "        # the BGR image to RGB.\n",
    "        \n",
    "        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)      \n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Draw the hand mesh annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                for n_point in range(len(results.multi_hand_landmarks[0].landmark)):\n",
    "                    palm_vector_list.append(hand_landmarks.landmark[n_point].x)\n",
    "                    palm_vector_list.append(hand_landmarks.landmark[n_point].y)                        \n",
    "                    palm_vector_list.append(hand_landmarks.landmark[n_point].z)                \n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS) \n",
    "\n",
    "            \n",
    "            prob=torch.tensor(np.array(palm_vector_list), dtype=torch.float, device=device)\n",
    "            prob=torch.reshape(prob, (1, X_data.shape[1]))\n",
    "            \n",
    "            result = net(prob)\n",
    "            \n",
    "            emotion = categoryFromOutput(result)[0]\n",
    "            \n",
    "            cv2.putText(image, \n",
    "                        emotion, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            \n",
    "            current_char = emotion\n",
    "            if current_char != pre_char:\n",
    "                gesture_name.append(current_char)\n",
    "                pre_char = current_char\n",
    "                \n",
    "                if current_char == 'Palm':\n",
    "                    count += 1  \n",
    "                    cv2.imwrite('screen/foto_' + str(current_char) + \"_\" + str(count) + '.jpg', image)\n",
    "\n",
    "                if current_char == 'Thumb':\n",
    "                    emotion = 'Hello'\n",
    "                    cv2.putText(image,\n",
    "                                emotion, (70, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.imshow('MediaPipe PalmMesh', image)\n",
    "\n",
    "        else:\n",
    "            emotion = 'No hand'\n",
    "            cv2.putText(image, \n",
    "                        emotion, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.namedWindow('MediaPipe PalmMesh', cv2.WINDOW_NORMAL)\n",
    "            cv2.imshow('MediaPipe PalmMesh', image)\n",
    "              \n",
    "            \n",
    "        # if cv2.waitKey(5) & 0xFF == 27:\n",
    "        #         break\n",
    "    \n",
    "        # For webcam work       \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "377db868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palm,  I,  Palm,  I,  Palm,  Ok,  Palm,  Thumb,  I,  Thumb,  I,  Palm,  Thumb,  I,  Thumb,  Ok,  Thumb,  Ok,  Thumb,  Ok,  Thumb,  Ok,  Palm,  Thumb,  Palm,  Ok,  Palm,  Thumb,  I,  Thumb,  I,  Thumb,  I,  Thumb,  I,  Thumb,  I,  Thumb,  I,  Thumb,  I,  Thumb,  I,  Palm,  I,  Palm,  I,  Thumb,  I,  Palm,  I,  Thumb,  Palm,  I,  Thumb,  I,  Thumb,  I,  Palm,  I,  Thumb,  I,  Palm,  I,  Palm,  Ok,  Palm,  Thumb,  Ok,  I,  Thumb,  Palm,  Ok,  Palm,  Thumb,  I,  Palm,  "
     ]
    }
   ],
   "source": [
    "# Журнал с распознанными жестами (gesture_name)\n",
    "for gest in gesture_name:\n",
    "    print(gest, end=',  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca559c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
